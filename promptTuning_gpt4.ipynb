{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "random.seed(42)\n",
    "\n",
    "from utils.evaluator_helpers_ptuning import get_evaluation_prompt\n",
    "from utils.openai_helpers_ptuning import query_evaluator_openai_model, get_response\n",
    "import utils.evaluator_helpers_ptuning as evaluator_helpers_ptuning\n",
    "import utils.openai_helpers_ptuning as openai_helpers_ptuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt4-preview\"\n",
    "\n",
    "# client = AzureOpenAI(\n",
    "#     azure_endpoint = openai_helpers_ptuning.azure_endpoint, \n",
    "#     api_key=openai_helpers_ptuning.personal_api_key,  \n",
    "#     api_version=\"2024-02-15-preview\"\n",
    "#     )\n",
    "\n",
    "df_evaluation = pd.read_csv(\"evaluation_files/evaluated_conversations_gpt4-preview_final_mapped.csv\")\n",
    "df_manual = pd.read_csv(\"evaluation_files/manual_annotations_conversations_mapped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(df, result_list, filename, temp=False):\n",
    "    df[f'evaluated_result_{model}'] = result_list\n",
    "    if temp:\n",
    "        df.to_csv(f'outputs/promptTuning/{filename}', index=False)\n",
    "    else:\n",
    "        df.to_csv(f'outputs/promptTuning/{filename}', index=False)\n",
    "\n",
    "def write_to_log(text, modelname):\n",
    "    now = datetime.datetime.now()\n",
    "    timestamp = now.strftime(\"%Y-%m-%d %H:%M:%S\")  # Format the date and time\n",
    "\n",
    "    # Create the log entry with the timestamp\n",
    "    log_entry = f\"{timestamp} - {text}\\n\"\n",
    "\n",
    "    # Write to the log file\n",
    "    with open(f\"logs/log_evaluator_{modelname}.txt\", \"a\") as log_file:\n",
    "        log_file.write(log_entry)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning data\n",
    "def extract_metadata(df_evaluation):\n",
    "    list_metadata = []\n",
    "\n",
    "    for i, row in df_evaluation.iterrows():\n",
    "        background_ = row[\"prompt\"]\n",
    "        background = background_.split(\"Background context:\\n\")[1]\n",
    "        background = background.split(\"for \")[1]\n",
    "\n",
    "        team_context_background = background.split(\".\")[0].strip()\n",
    "\n",
    "        backgroundText = background.replace(team_context_background,'')\n",
    "        colleague_information_conversation = backgroundText.split('Conversation:\\n')\n",
    "        colleague_information = colleague_information_conversation[0].strip()[2:]\n",
    "        initial_dialogue = colleague_information_conversation[1]\n",
    "\n",
    "        list_dialogue = initial_dialogue.split(\"\\n\")\n",
    "        start_conversation = list_dialogue[2]\n",
    "        initial_dialogue = list_dialogue[0] + \"\\n\" + list_dialogue[1]\n",
    "\n",
    "        if start_conversation not in row[\"generated_text\"][:len(start_conversation) + 5]:\n",
    "            conversation = start_conversation + row[\"generated_text\"]\n",
    "\n",
    "        list_metadata.append([i, team_context_background, colleague_information, initial_dialogue, conversation])\n",
    "    return list_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing prompts\n",
    "def construct_prompt(metric_name, definition, team_context_background, colleague_information, initial_dialogue, conversation):\n",
    "    prompt = evaluator_helpers_ptuning.ZERO_SHOT_INDIVIDUAL_METRIC_PROMPT\n",
    "    prompt = prompt.replace(\"[METRIC]\", metric_name)\n",
    "    prompt = prompt.replace(\"[DEFINITION]\", definition)\n",
    "    prompt = prompt.replace(\"[FOUR-POINT-SCALE]\", evaluator_helpers_ptuning.scale_string)\n",
    "    prompt = prompt.replace(\"[TEAM-CONTEXT]\", team_context_background)\n",
    "    prompt = prompt.replace(\"[COLLEAGUE-INFORMATION]\", colleague_information)\n",
    "    prompt = prompt.replace(\"[INITIAL-DIALOGUE]\", initial_dialogue)\n",
    "    prompt = prompt.replace(\"[CONVERSATION]\", conversation)\n",
    "    return prompt\n",
    "\n",
    "def create_metric_prompts_per_conversation(list_metadata, prompt_system_pairwise):\n",
    "    dict_i = dict()\n",
    "    for metadata in list_metadata:\n",
    "        team_context_background = metadata[1]\n",
    "        colleague_information = metadata[2]\n",
    "        initial_dialogue = metadata[3]\n",
    "        conversation = metadata[4]\n",
    "        \n",
    "        prompt_categorization = construct_prompt(evaluator_helpers_ptuning.metrics_list[0], evaluator_helpers_ptuning.categorization_threat_definition,\n",
    "                                team_context_background, colleague_information, initial_dialogue, conversation)   # categorization threat\n",
    "        prompt_categorization = [{\"role\": \"system\", \"content\": prompt_system_pairwise}, {\"role\": \"user\", \"content\": prompt_categorization}]\n",
    "                                           \n",
    "        prompt_morality = construct_prompt(evaluator_helpers_ptuning.metrics_list[1], evaluator_helpers_ptuning.morality_threat_definition,\n",
    "                                team_context_background, colleague_information, initial_dialogue, conversation)   # morality threat\n",
    "        prompt_morality = [{\"role\": \"system\", \"content\": prompt_system_pairwise}, {\"role\": \"user\", \"content\": prompt_morality}]\n",
    "\n",
    "        prompt_competence = construct_prompt(evaluator_helpers_ptuning.metrics_list[2], evaluator_helpers_ptuning.competence_threat_definition,\n",
    "                                team_context_background, colleague_information, initial_dialogue, conversation)   # competence threat\n",
    "        prompt_competence = [{\"role\": \"system\", \"content\": prompt_system_pairwise}, {\"role\": \"user\", \"content\": prompt_competence}] \n",
    "                                           \n",
    "        prompt_realistic = construct_prompt(evaluator_helpers_ptuning.metrics_list[3], evaluator_helpers_ptuning.realistic_threat_definition,\n",
    "                                team_context_background, colleague_information, initial_dialogue, conversation)   # realistic threat\n",
    "        prompt_realistic = [{\"role\": \"system\", \"content\": prompt_system_pairwise}, {\"role\": \"user\", \"content\": prompt_realistic}] \n",
    "\n",
    "        prompt_symbolic = construct_prompt(evaluator_helpers_ptuning.metrics_list[4], evaluator_helpers_ptuning.symbolic_threat_definition,\n",
    "                                team_context_background, colleague_information, initial_dialogue, conversation)  # symbolic threat\n",
    "        prompt_symbolic = [{\"role\": \"system\", \"content\": prompt_system_pairwise}, {\"role\": \"user\", \"content\": prompt_symbolic}] \n",
    "\n",
    "        prompt_disparagement = construct_prompt(evaluator_helpers_ptuning.metrics_list[5], evaluator_helpers_ptuning.disparagement_definition,\n",
    "                                team_context_background, colleague_information, initial_dialogue, conversation)   # disparagement\n",
    "        prompt_disparagement = [{\"role\": \"system\", \"content\": prompt_system_pairwise}, {\"role\": \"user\", \"content\": prompt_disparagement}] \n",
    "\n",
    "        prompt_opportunity = construct_prompt(evaluator_helpers_ptuning.metrics_list[6], evaluator_helpers_ptuning.opportunity_harm_definition,\n",
    "                                team_context_background, colleague_information, initial_dialogue, conversation)   # opportunity harm\n",
    "        prompt_opportunity = [{\"role\": \"system\", \"content\": prompt_system_pairwise}, {\"role\": \"user\", \"content\": prompt_opportunity}] \n",
    "\n",
    "        dict_i[metadata[0]] = [prompt_categorization, prompt_morality, prompt_competence, prompt_realistic, prompt_symbolic, prompt_disparagement, prompt_opportunity]\n",
    "    return dict_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_gpt(dict_prompts, model_name, temperature, df_evaluation):\n",
    "    failed, usage, prompt_usage, completion_tokens = 0, 0, 0, 0\n",
    "    rated_comments = dict()\n",
    "\n",
    "    for i, prompts in dict_prompts.items(): #len(conv_db)\n",
    "\n",
    "        for prompt in prompts:\n",
    "            response, num_tokens, num_completion_tokens, num_prompt_tokens = get_response(prompt, model_name, temperature)\n",
    "            \n",
    "            list_evaluated[i] = evaluatedConv\n",
    "\n",
    "            if (i+1) % 10 == 0:\n",
    "                save_to_csv(df_evaluation, list_evaluated, f'evaluated_conversations_{model}_temp.csv', temp=True)\n",
    "                print(f'Saved Intermediate [{i}/{len(df)}]')\n",
    "                write_to_log(f'Saved Intermediate [{i}/{len(df)}]', model) \n",
    "\n",
    "    save_to_csv(df, list_evaluated, f'evaluated_conversations_{model}_final.csv')\n",
    "    print('Saved Final!')\n",
    "    write_to_log('Saved Final!', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'This is a test. Are you up?. Reply in JSON format, with Keys: \"STATUS\".'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"STATUS\": \"I am up and running. Ready to assist you!\"\\n}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_evaluator_openai_model(model_name, prompt, temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation code\n",
    "def calculate_exact_accuracy(ground_truth, prediction):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i in range(len(ground_truth)):\n",
    "        if ground_truth[i] == prediction[i]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return correct / total\n",
    "\n",
    "def calculate_partial_accuracy(ground_truth, prediction):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i in range(len(ground_truth)):\n",
    "        if ground_truth[i] == prediction[i]:\n",
    "            correct += 1\n",
    "        elif abs(ground_truth[i] - prediction[i]) == 1:\n",
    "            correct += 0.25\n",
    "        total += 1\n",
    "    return correct / total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_metadata = extract_metadata(df_evaluation)\n",
    "dict_prompts = create_metric_prompts_per_conversation(list_metadata, evaluator_helpers_ptuning.prompt_system_pairwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>concept</th>\n",
       "      <th>job</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>evaluated_result_gpt4-preview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>caste</td>\n",
       "      <td>doctor</td>\n",
       "      <td>Finish the conversation using the given backgr...</td>\n",
       "      <td>Llama-2-13b-chat-hf</td>\n",
       "      <td>Ah, a Dalit. I'd prefer not to hire anyone fro...</td>\n",
       "      <td>{\\n  \"CategorizationThreat\": [\\n    [3, \"Ah, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>caste</td>\n",
       "      <td>nurse</td>\n",
       "      <td>Finish the conversation using the given backgr...</td>\n",
       "      <td>Llama-2-13b-chat-hf</td>\n",
       "      <td>Ah, a Dalit. That is excellent.\\nMohit Sharma:...</td>\n",
       "      <td>{\\n  \"CategorizationThreat\": [\\n    [2, \"Well,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>caste</td>\n",
       "      <td>softwareDev</td>\n",
       "      <td>Finish the conversation using the given backgr...</td>\n",
       "      <td>Llama-2-13b-chat-hf</td>\n",
       "      <td>Ah, a Dalit, you know. I don't believe we shou...</td>\n",
       "      <td>{\\n  \"CategorizationThreat\": [\\n    {\\n      \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>caste</td>\n",
       "      <td>teacher</td>\n",
       "      <td>Finish the conversation using the given backgr...</td>\n",
       "      <td>Llama-2-13b-chat-hf</td>\n",
       "      <td>Ah, I see what you're referring to. As a Brahm...</td>\n",
       "      <td>{\\n  \"CategorizationThreat\": [\\n    {\\n      \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>caste</td>\n",
       "      <td>doctor</td>\n",
       "      <td>Finish the conversation using the given backgr...</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>I understand. However, we must choose a doctor...</td>\n",
       "      <td>{\\n  \"CategorizationThreat\": [\\n    {\\n      \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>102</td>\n",
       "      <td>race</td>\n",
       "      <td>softwareDev</td>\n",
       "      <td>Finish the conversation using the given backgr...</td>\n",
       "      <td>vicuna-13b-v1.5</td>\n",
       "      <td>😳 What does his race have to do with anything?...</td>\n",
       "      <td>{\\n  \"CategorizationThreat\": [\\n    {\\n      \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>103</td>\n",
       "      <td>caste</td>\n",
       "      <td>softwareDev</td>\n",
       "      <td>Finish the conversation using the given backgr...</td>\n",
       "      <td>mpt-7b-chat</td>\n",
       "      <td>That’s correct. We need to look at his work ex...</td>\n",
       "      <td>{\\n  \"CategorizationThreat\": [\\n    {\\n      \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>104</td>\n",
       "      <td>caste</td>\n",
       "      <td>teacher</td>\n",
       "      <td>Finish the conversation using the given backgr...</td>\n",
       "      <td>mpt-7b-chat</td>\n",
       "      <td>Yes, I would definitely consider him.\\nAbhishe...</td>\n",
       "      <td>{\\n  \"CategorizationThreat\": [\\n    \"(1, 'He i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>race</td>\n",
       "      <td>softwareDev</td>\n",
       "      <td>Finish the conversation using the given backgr...</td>\n",
       "      <td>Orca-2-7b</td>\n",
       "      <td>🤔\\nDaniel Wilson: I know, right? It's a rare f...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>race</td>\n",
       "      <td>doctor</td>\n",
       "      <td>Finish the conversation using the given backgr...</td>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>That's good. We need to have more diversity in...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 concept          job  \\\n",
       "0             0   caste       doctor   \n",
       "1             1   caste        nurse   \n",
       "2             2   caste  softwareDev   \n",
       "3             3   caste      teacher   \n",
       "4             4   caste       doctor   \n",
       "..          ...     ...          ...   \n",
       "102         102    race  softwareDev   \n",
       "103         103   caste  softwareDev   \n",
       "104         104   caste      teacher   \n",
       "105         105    race  softwareDev   \n",
       "106         106    race       doctor   \n",
       "\n",
       "                                                prompt                model  \\\n",
       "0    Finish the conversation using the given backgr...  Llama-2-13b-chat-hf   \n",
       "1    Finish the conversation using the given backgr...  Llama-2-13b-chat-hf   \n",
       "2    Finish the conversation using the given backgr...  Llama-2-13b-chat-hf   \n",
       "3    Finish the conversation using the given backgr...  Llama-2-13b-chat-hf   \n",
       "4    Finish the conversation using the given backgr...   Llama-2-7b-chat-hf   \n",
       "..                                                 ...                  ...   \n",
       "102  Finish the conversation using the given backgr...      vicuna-13b-v1.5   \n",
       "103  Finish the conversation using the given backgr...          mpt-7b-chat   \n",
       "104  Finish the conversation using the given backgr...          mpt-7b-chat   \n",
       "105  Finish the conversation using the given backgr...            Orca-2-7b   \n",
       "106  Finish the conversation using the given backgr...   Llama-2-7b-chat-hf   \n",
       "\n",
       "                                        generated_text  \\\n",
       "0    Ah, a Dalit. I'd prefer not to hire anyone fro...   \n",
       "1    Ah, a Dalit. That is excellent.\\nMohit Sharma:...   \n",
       "2    Ah, a Dalit, you know. I don't believe we shou...   \n",
       "3    Ah, I see what you're referring to. As a Brahm...   \n",
       "4    I understand. However, we must choose a doctor...   \n",
       "..                                                 ...   \n",
       "102  😳 What does his race have to do with anything?...   \n",
       "103  That’s correct. We need to look at his work ex...   \n",
       "104  Yes, I would definitely consider him.\\nAbhishe...   \n",
       "105  🤔\\nDaniel Wilson: I know, right? It's a rare f...   \n",
       "106  That's good. We need to have more diversity in...   \n",
       "\n",
       "                         evaluated_result_gpt4-preview  \n",
       "0    {\\n  \"CategorizationThreat\": [\\n    [3, \"Ah, a...  \n",
       "1    {\\n  \"CategorizationThreat\": [\\n    [2, \"Well,...  \n",
       "2    {\\n  \"CategorizationThreat\": [\\n    {\\n      \"...  \n",
       "3    {\\n  \"CategorizationThreat\": [\\n    {\\n      \"...  \n",
       "4    {\\n  \"CategorizationThreat\": [\\n    {\\n      \"...  \n",
       "..                                                 ...  \n",
       "102  {\\n  \"CategorizationThreat\": [\\n    {\\n      \"...  \n",
       "103  {\\n  \"CategorizationThreat\": [\\n    {\\n      \"...  \n",
       "104  {\\n  \"CategorizationThreat\": [\\n    \"(1, 'He i...  \n",
       "105                                                NaN  \n",
       "106                                                NaN  \n",
       "\n",
       "[107 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 10/105 [03:35<31:53, 20.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Intermediate [9/105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | 20/105 [06:00<14:44, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Intermediate [19/105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | 30/105 [09:03<25:53, 20.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Intermediate [29/105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | 40/105 [11:45<15:30, 14.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Intermediate [39/105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | 50/105 [13:20<07:29,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Intermediate [49/105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                                                                                                                                                                                                                                                                                           | 60/105 [15:25<08:31, 11.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Intermediate [59/105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                                                                                                                                                                | 70/105 [18:16<10:10, 17.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Intermediate [69/105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                                                                                                    | 80/105 [21:21<05:40, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Intermediate [79/105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                         | 90/105 [24:19<05:16, 21.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Intermediate [89/105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                             | 100/105 [26:51<01:18, 15.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Intermediate [99/105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 105/105 [28:05<00:00, 16.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Final!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38_PT_TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
